{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94de9a2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "load_dotenv('/Users/asze01/Code/Hassoun-Lab/GPT.env')\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"API key not found. Please check your .env file.\")\n",
    "\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Currently are still placeholders\n",
    "input_csv = \"input_papers.csv\"\n",
    "output_csv = \"output_papers_with_workflows.csv\"\n",
    "\n",
    "# Currently are still placeholders\n",
    "full_text_col = \"full_text\"              # column 1 (?): text of the paper\n",
    "workflow_output_col = \"workflow_json\"    # column 2 (? new): output template with workflow + more (depends)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e11d9b-194c-48ca-a150-4773a5c12544",
   "metadata": {},
   "source": [
    "The following chunk is for extracting workflows from papers. It is work in progress until the following conditions are met:\n",
    "- the 20 manually annotated papers are done -> JSON template and prompt can be fully optimized\n",
    "- All papers (and their figures) are processed into text -> full text for extraction is ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7095e77-4536-4533-9c57-a14e9f5151ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt for extracting workflow\n",
    "# Should be iterated upon after testing to see if the workflows extracted meet the standard of our manual extractions\n",
    "workflow_prompt_instructions = \"\"\"\n",
    "You are an expert in untargeted metabolomics and workflow design.\n",
    "\n",
    "Given the full text of a metabolomics paper, extract ONLY the untargeted metabolomics workflow\n",
    "used in the study. Focus on the main experimental and computational steps, in execution order.\n",
    "The workflow you extract should be detailed enough for a researcher to read and carry out.\n",
    "Do not omit any details directly relevant to the workflow. Include any relevant tools/APIs/databases\n",
    "used in the workflow.\n",
    "\n",
    "Guidelines:\n",
    "- Include only steps that are explicitly described or clearly implied from the text.\n",
    "- Do NOT invent tools, databases, or steps that are not supported by the paper.\n",
    "- Use concise, technical language suitable for a computational systems biology researcher.\n",
    "- If something is missing or unclear in the paper, mark it as \"unspecified\" rather than guessing.\n",
    "\n",
    "Return your answer as JSON following the provided schema exactly.\n",
    "\"\"\"\n",
    "\n",
    "# JSON Schema (modify after we do the 20 annotated examples)\n",
    "response_format = {\n",
    "    \"type\": \"json_schema\",\n",
    "    \"json_schema\": {\n",
    "        \"name\": \"metabolomics_workflow_extraction\",\n",
    "        \"schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"paper_has_untargeted_metabolomics\": {\"type\": \"boolean\"},\n",
    "                \"workflow_steps\": {\n",
    "                    \"type\": \"array\",\n",
    "                    \"items\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"step_number\": {\"type\": \"integer\"},\n",
    "                            \"step_name\": {\"type\": \"string\"},\n",
    "                            \"description\": {\"type\": \"string\"},\n",
    "                            \"category\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"High-level category (e.g., sample prep, LC-MS acquisition, preprocessing, feature extraction, normalization, statistics, annotation, pathway analysis)\"\n",
    "                            },\n",
    "                            \"tools_software\": {\n",
    "                                \"type\": \"array\",\n",
    "                                \"items\": {\"type\": \"string\"}\n",
    "                            },\n",
    "                            \"databases_apis\": {\n",
    "                                \"type\": \"array\",\n",
    "                                \"items\": {\"type\": \"string\"}\n",
    "                            },\n",
    "                            \"inputs\": {\n",
    "                                \"type\": \"array\",\n",
    "                                \"items\": {\"type\": \"string\"}\n",
    "                            },\n",
    "                            \"outputs\": {\n",
    "                                \"type\": \"array\",\n",
    "                                \"items\": {\"type\": \"string\"}\n",
    "                            },\n",
    "                            \"is_explicit_in_paper\": {\n",
    "                                \"type\": \"boolean\",\n",
    "                                \"description\": \"True if this step is explicitly described; false if strongly implied.\"\n",
    "                            }\n",
    "                        },\n",
    "                        \"required\": [\n",
    "                            \"step_number\",\n",
    "                            \"step_name\",\n",
    "                            \"description\",\n",
    "                            \"category\",\n",
    "                            \"tools_software\",\n",
    "                            \"databases_apis\",\n",
    "                            \"inputs\",\n",
    "                            \"outputs\",\n",
    "                            \"is_explicit_in_paper\"\n",
    "                        ]\n",
    "                    }\n",
    "                },\n",
    "                \"unspecified_or_omitted_steps\": {\n",
    "                    \"type\": \"array\",\n",
    "                    \"items\": {\"type\": \"string\"},\n",
    "                    \"description\": \"Important steps that seem missing or under-specified.\"\n",
    "                },\n",
    "                \"notes_on_ambiguity\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Short explanation of any ambiguities or uncertainties in the extracted workflow.\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\n",
    "                \"paper_has_untargeted_metabolomics\",\n",
    "                \"workflow_steps\",\n",
    "                \"unspecified_or_omitted_steps\",\n",
    "                \"notes_on_ambiguity\"\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9600b8cd-7523-4f1f-b718-03f8bb07b8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the GPT model to extract the metabolomics workflow from a paper's full text.\n",
    "# Returns a Python dict following the response_format JSON schema.\n",
    "# On failure, returns a dict with error information.\n",
    "\n",
    "def extract_workflow_from_full_text(full_text: str,\n",
    "                                    max_retries: int = 3,\n",
    "                                    retry_delay: float = 5.0):\n",
    "\n",
    "    user_prompt = (\n",
    "        f\"{workflow_prompt_instructions.strip()}\\n\\n\"\n",
    "        \"Full paper text:\\n\"\n",
    "        f\"{full_text.strip()}\\n\"\n",
    "    )\n",
    "\n",
    "    for attempt in range(1, max_retries + 1):\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-5-nano\",\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"system\",\n",
    "                        \"content\": \"You are a precise assistant that does not hallucinate or create new information for extracting workflows from scientific papers.\"\n",
    "                    },\n",
    "                    {\"role\": \"user\", \"content\": user_prompt}\n",
    "                ],\n",
    "                temperature=0.0,\n",
    "                response_format=response_format\n",
    "            )\n",
    "            raw = response.choices[0].message.content.strip()\n",
    "            # Because response_format enforces JSON, we can parse directly\n",
    "            result = json.loads(raw)\n",
    "            return result\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[Attempt {attempt}] Error extracting workflow: {e}\")\n",
    "            if attempt == max_retries:\n",
    "                # Give up and return an error payload\n",
    "                return {\n",
    "                    \"paper_has_untargeted_metabolomics\": False,\n",
    "                    \"workflow_steps\": [],\n",
    "                    \"unspecified_or_omitted_steps\": [],\n",
    "                    \"notes_on_ambiguity\": f\"Extraction failed after {max_retries} attempts: {e}\"\n",
    "                }\n",
    "            time.sleep(retry_delay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb18ec30-8cc2-4dbe-bb3a-2267b8e22cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    df = pd.read_csv(input_csv)\n",
    "\n",
    "    if full_text_col not in df.columns:\n",
    "        raise ValueError(f\"Column '{full_text_col}' not found in input CSV.\")\n",
    "\n",
    "    df[workflow_output_col] = None\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        full_text = str(row[full_text_col]).strip()\n",
    "\n",
    "        if not full_text:\n",
    "            print(f\"Row {idx}: empty full_text, skipping.\")\n",
    "            df.at[idx, workflow_output_col] = json.dumps({\n",
    "                \"paper_has_untargeted_metabolomics\": False,\n",
    "                \"workflow_steps\": [],\n",
    "                \"unspecified_or_omitted_steps\": [],\n",
    "                \"notes_on_ambiguity\": \"No full text provided.\"\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        print(f\"Processing row {idx} (first 80 chars): {full_text[:80].replace('\\\\n', ' ')}...\")\n",
    "\n",
    "        workflow_result = extract_workflow_from_full_text(full_text)\n",
    "\n",
    "        df.at[idx, workflow_output_col] = json.dumps(workflow_result, ensure_ascii=False)\n",
    "\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"Saved augmented CSV to: {output_csv}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6065ab-d73e-4bf7-9ea5-b35df8687edb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
